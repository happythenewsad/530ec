{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, \".\")\n",
    "\n",
    "from Utils import Utils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Utils.file_to_vocab(\"./data/en-train.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple baseline\n",
    "#Utils.gen_baseline_labels(\"./data/en-test.txt\", \"./simple_baseline_test.txt\", vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_Y = Utils.extract_labels('./data/en-train.txt')\n",
    "train_Y = np.array(train_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate cosine feature on training data and save\n",
    "# import pickle \n",
    "# with open('./data/en-train.txt','r') as f1:\n",
    "#     lines = f1.readlines()\n",
    "\n",
    "# # extract cosine feature\n",
    "# cosine_sim_feature = Utils.gen_cosine_sim_feature(lines, vocab, stem=True)\n",
    "# train_X = np.array(cosine_sim_feature)\n",
    "# pickle.dump(train_X,open(\"feature_train_cosine.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils import Utils\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "# generate NER and POS features\n",
    "features_by_row = Utils.gen_pos_ner_features('./data/en-train.txt')\n",
    "vectorizer = DictVectorizer()\n",
    "X_train_ner_pos = vectorizer.fit_transform(features_by_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "pickle.dump(X_train_ner_pos,open(\"feature_train_pos.pickle\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine features if necessary into X_train\n",
    "\n",
    "import pickle\n",
    "import codecs\n",
    "import numpy as np\n",
    "from scipy import sparse\n",
    "\n",
    "with codecs.open(\"feature_train_cosine.pickle\",'rb', errors='ignore') as f1:\n",
    "    cosine_feature = pickle.load(f1)\n",
    "    cosine_feature = np.array([[i] for i in cosine_feature])\n",
    "    \n",
    "with codecs.open(\"feature_train_pos.pickle\",'rb', errors='ignore') as f1:\n",
    "    pos_features = pickle.load(f1)\n",
    "  \n",
    "train_X = sparse.hstack([pos_features, cosine_feature])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KernelRidge(alpha=1.0, coef0=1, degree=3, gamma=None, kernel='linear',\n",
       "      kernel_params=None)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train KernelRidge model\n",
    "\n",
    "    \n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "krm = KernelRidge(alpha=1.0)\n",
    "krm.fit(train_X, train_Y) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 3.5355339059327373\n",
      "1000 1.5430334996209194\n"
     ]
    }
   ],
   "source": [
    "mode = 'test'\n",
    "\n",
    "val_Y = Utils.extract_labels('./data/en-' + mode + '.txt')\n",
    "val_Y = np.array(val_Y)\n",
    "\n",
    "with open('./data/en-val.txt','r') as f1:\n",
    "    lines = f1.readlines()\n",
    "\n",
    "# extract cosine feature\n",
    "cosine_sim_feature = Utils.gen_cosine_sim_feature(lines, vocab, stem=True)\n",
    "cosine_sim_feature = np.array([[i] for i in cosine_sim_feature])\n",
    "#val_X = np.array(cosine_sim_feature).reshape(-1,1)\n",
    "\n",
    "features_by_row = Utils.gen_pos_ner_features('./data/en-val.txt')\n",
    "vectorizer = DictVectorizer()\n",
    "X_val_ner_pos = vectorizer.fit_transform(features_by_row)\n",
    "val_X = sparse.hstack([X_val_ner_pos, cosine_sim_feature])\n",
    "\n",
    "val_Y_pred = krm.predict(val_X)\n",
    "\n",
    "with open('val_y_pred.txt', 'w') as f:      \n",
    "    for score in val_Y_pred:\n",
    "        f.write(\"{}\\n\".format(score)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
